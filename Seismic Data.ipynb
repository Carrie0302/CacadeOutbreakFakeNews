{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relative_time_second</th>\n",
       "      <th>number_of_followers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84833.0</td>\n",
       "      <td>46828.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84878.0</td>\n",
       "      <td>208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84883.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84900.0</td>\n",
       "      <td>137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34784483</th>\n",
       "      <td>103297.0</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34784484</th>\n",
       "      <td>108205.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34784485</th>\n",
       "      <td>109345.0</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34784486</th>\n",
       "      <td>158677.0</td>\n",
       "      <td>391.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34784487</th>\n",
       "      <td>346830.0</td>\n",
       "      <td>699.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34784488 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          relative_time_second  number_of_followers\n",
       "0                          0.0                 33.0\n",
       "1                      84833.0              46828.0\n",
       "2                      84878.0                208.0\n",
       "3                      84883.0                 37.0\n",
       "4                      84900.0                137.0\n",
       "...                        ...                  ...\n",
       "34784483              103297.0                110.0\n",
       "34784484              108205.0                 24.0\n",
       "34784485              109345.0                151.0\n",
       "34784486              158677.0                391.0\n",
       "34784487              346830.0                699.0\n",
       "\n",
       "[34784488 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "TwitterSEISMIC Dataset\n",
    "  <relative_time_second>: relative post time of the tweet/retweet (in second)\n",
    "  <number_of_followers>: number of followers of the user who tweets/retweets\n",
    "\"\"\"\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166076, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "TwitterSEISMIC Index\n",
    "  <tweet_id>: id of the original tweet\n",
    "  <post_time_day>: post time (UTC) of the original tweet (in day)\n",
    "  <start_ind>: the first row in data.csv of this tweet\n",
    "  <end_ind>: the last row in data.csv of this tweet \n",
    "\"\"\"\n",
    "from datetime import datetime\n",
    "index = pd.read_csv(\"index.csv\")\n",
    "index['post_date'] = pd.to_datetime(index['post_time_day'], unit='D', origin=pd.Timestamp('2011-10-07'))\n",
    "index['total_retweets_over_15_days'] = index[\"end_ind\"] - index[\"start_ind\"]\n",
    "index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relative_time_second</th>\n",
       "      <th>number_of_followers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>34784488.00000</td>\n",
       "      <td>34784488.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>39158.58904</td>\n",
       "      <td>2774.20607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>89030.89850</td>\n",
       "      <td>64880.14996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>334.00000</td>\n",
       "      <td>50.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3209.00000</td>\n",
       "      <td>120.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>29312.00000</td>\n",
       "      <td>286.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>604799.00000</td>\n",
       "      <td>14755952.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       relative_time_second  number_of_followers\n",
       "count        34784488.00000       34784488.00000\n",
       "mean            39158.58904           2774.20607\n",
       "std             89030.89850          64880.14996\n",
       "min                 0.00000              0.00000\n",
       "25%               334.00000             50.00000\n",
       "50%              3209.00000            120.00000\n",
       "75%             29312.00000            286.00000\n",
       "max            604799.00000       14755952.00000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = lambda x : '{:.5f}'.format(x)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>post_time_day</th>\n",
       "      <th>start_ind</th>\n",
       "      <th>end_ind</th>\n",
       "      <th>post_date</th>\n",
       "      <th>total_retweets_over_15_days</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outbreak</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>162945</td>\n",
       "      <td>162945</td>\n",
       "      <td>162945</td>\n",
       "      <td>162945</td>\n",
       "      <td>162945</td>\n",
       "      <td>162945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>3131</td>\n",
       "      <td>3131</td>\n",
       "      <td>3131</td>\n",
       "      <td>3131</td>\n",
       "      <td>3131</td>\n",
       "      <td>3131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tweet_id  post_time_day  start_ind  end_ind  post_date  \\\n",
       "outbreak                                                           \n",
       "False       162945         162945     162945   162945     162945   \n",
       "True          3131           3131       3131     3131       3131   \n",
       "\n",
       "          total_retweets_over_15_days  \n",
       "outbreak                               \n",
       "False                          162945  \n",
       "True                             3131  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Identify cascades in the network\n",
    "    2% tweets were selected as outbreak tweets according to their final retweets and the minimum retweet\n",
    "    number of outbreak tweets was selected as the outbreak threshold\n",
    "    3131 outbreak tweets with the outbreak threshold was 1000 \n",
    "\"\"\"\n",
    "index['outbreak'] = index['total_retweets_over_15_days'] > 1000\n",
    "total_tweets_s =  index # index.sort_values(by='total_retweets_over_15_days', ascending = False)\n",
    "total_tweets_s.groupby('outbreak').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>post_time_day</th>\n",
       "      <th>start_ind</th>\n",
       "      <th>end_ind</th>\n",
       "      <th>total_retweets_over_15_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.660760e+05</td>\n",
       "      <td>166076.000000</td>\n",
       "      <td>1.660760e+05</td>\n",
       "      <td>1.660760e+05</td>\n",
       "      <td>166076.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.250288e+17</td>\n",
       "      <td>8.085091</td>\n",
       "      <td>1.745785e+07</td>\n",
       "      <td>1.745805e+07</td>\n",
       "      <td>208.449216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.492892e+15</td>\n",
       "      <td>4.119661</td>\n",
       "      <td>1.011126e+07</td>\n",
       "      <td>1.011126e+07</td>\n",
       "      <td>396.576751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.222060e+17</td>\n",
       "      <td>0.294514</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.750000e+02</td>\n",
       "      <td>49.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.237590e+17</td>\n",
       "      <td>4.580842</td>\n",
       "      <td>8.740974e+06</td>\n",
       "      <td>8.741077e+06</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.250000e+17</td>\n",
       "      <td>8.006973</td>\n",
       "      <td>1.728315e+07</td>\n",
       "      <td>1.728324e+07</td>\n",
       "      <td>110.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.263740e+17</td>\n",
       "      <td>11.797674</td>\n",
       "      <td>2.614600e+07</td>\n",
       "      <td>2.614647e+07</td>\n",
       "      <td>219.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.275350e+17</td>\n",
       "      <td>14.999873</td>\n",
       "      <td>3.478441e+07</td>\n",
       "      <td>3.478449e+07</td>\n",
       "      <td>33484.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tweet_id  post_time_day     start_ind       end_ind  \\\n",
       "count  1.660760e+05  166076.000000  1.660760e+05  1.660760e+05   \n",
       "mean   1.250288e+17       8.085091  1.745785e+07  1.745805e+07   \n",
       "std    1.492892e+15       4.119661  1.011126e+07  1.011126e+07   \n",
       "min    1.222060e+17       0.294514  1.000000e+00  1.750000e+02   \n",
       "25%    1.237590e+17       4.580842  8.740974e+06  8.741077e+06   \n",
       "50%    1.250000e+17       8.006973  1.728315e+07  1.728324e+07   \n",
       "75%    1.263740e+17      11.797674  2.614600e+07  2.614647e+07   \n",
       "max    1.275350e+17      14.999873  3.478441e+07  3.478449e+07   \n",
       "\n",
       "       total_retweets_over_15_days  \n",
       "count                166076.000000  \n",
       "mean                    208.449216  \n",
       "std                     396.576751  \n",
       "min                      49.000000  \n",
       "25%                      70.000000  \n",
       "50%                     110.000000  \n",
       "75%                     219.000000  \n",
       "max                   33484.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "total_tweets_s.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>start_ind</th>\n",
       "      <th>end_ind</th>\n",
       "      <th>post_date</th>\n",
       "      <th>total_retweets_over_15_days</th>\n",
       "      <th>outbreak</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post_time_day</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.294514</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.295231</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.297766</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.298090</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.300127</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.999780</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.999792</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.999803</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.999861</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.999873</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151906 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweet_id  start_ind  end_ind  post_date  \\\n",
       "post_time_day                                            \n",
       "0.294514              1          1        1          1   \n",
       "0.295231              1          1        1          1   \n",
       "0.297766              1          1        1          1   \n",
       "0.298090              1          1        1          1   \n",
       "0.300127              1          1        1          1   \n",
       "...                 ...        ...      ...        ...   \n",
       "14.999780             1          1        1          1   \n",
       "14.999792             1          1        1          1   \n",
       "14.999803             1          1        1          1   \n",
       "14.999861             1          1        1          1   \n",
       "14.999873             1          1        1          1   \n",
       "\n",
       "               total_retweets_over_15_days  outbreak  \n",
       "post_time_day                                         \n",
       "0.294514                                 1         1  \n",
       "0.295231                                 1         1  \n",
       "0.297766                                 1         1  \n",
       "0.298090                                 1         1  \n",
       "0.300127                                 1         1  \n",
       "...                                    ...       ...  \n",
       "14.999780                                1         1  \n",
       "14.999792                                1         1  \n",
       "14.999803                                1         1  \n",
       "14.999861                                1         1  \n",
       "14.999873                                1         1  \n",
       "\n",
       "[151906 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_tweets_dates =  index\n",
    "total_tweets_dates.groupby('post_time_day').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_stop = index[['start_ind', 'end_ind']].values.tolist()\n",
    "start_stop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>post_time_day</th>\n",
       "      <th>start_ind</th>\n",
       "      <th>end_ind</th>\n",
       "      <th>post_date</th>\n",
       "      <th>total_retweets_over_15_days</th>\n",
       "      <th>outbreak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.224350e+17</td>\n",
       "      <td>0.926644</td>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>2011-10-07 22:14:22.000041600</td>\n",
       "      <td>174</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.224500e+17</td>\n",
       "      <td>0.968160</td>\n",
       "      <td>176</td>\n",
       "      <td>369</td>\n",
       "      <td>2011-10-07 23:14:08.999980800</td>\n",
       "      <td>193</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.224500e+17</td>\n",
       "      <td>0.969560</td>\n",
       "      <td>370</td>\n",
       "      <td>703</td>\n",
       "      <td>2011-10-07 23:16:09.999984000</td>\n",
       "      <td>333</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.224430e+17</td>\n",
       "      <td>0.949734</td>\n",
       "      <td>704</td>\n",
       "      <td>827</td>\n",
       "      <td>2011-10-07 22:47:36.999974400</td>\n",
       "      <td>123</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.224570e+17</td>\n",
       "      <td>0.987373</td>\n",
       "      <td>828</td>\n",
       "      <td>941</td>\n",
       "      <td>2011-10-07 23:41:48.999984000</td>\n",
       "      <td>113</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166071</th>\n",
       "      <td>1.250010e+17</td>\n",
       "      <td>8.007164</td>\n",
       "      <td>34784039</td>\n",
       "      <td>34784103</td>\n",
       "      <td>2011-10-15 00:10:19.000012800</td>\n",
       "      <td>64</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166072</th>\n",
       "      <td>1.250010e+17</td>\n",
       "      <td>8.007407</td>\n",
       "      <td>34784104</td>\n",
       "      <td>34784155</td>\n",
       "      <td>2011-10-15 00:10:39.999964800</td>\n",
       "      <td>51</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166073</th>\n",
       "      <td>1.259250e+17</td>\n",
       "      <td>10.559387</td>\n",
       "      <td>34784156</td>\n",
       "      <td>34784320</td>\n",
       "      <td>2011-10-17 13:25:30.999648000</td>\n",
       "      <td>164</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166074</th>\n",
       "      <td>1.255490e+17</td>\n",
       "      <td>9.519977</td>\n",
       "      <td>34784321</td>\n",
       "      <td>34784412</td>\n",
       "      <td>2011-10-16 12:28:46.000012800</td>\n",
       "      <td>91</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166075</th>\n",
       "      <td>1.254170e+17</td>\n",
       "      <td>9.156794</td>\n",
       "      <td>34784413</td>\n",
       "      <td>34784488</td>\n",
       "      <td>2011-10-16 03:45:46.999958400</td>\n",
       "      <td>75</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166076 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            tweet_id  post_time_day  start_ind   end_ind  \\\n",
       "0       1.224350e+17       0.926644          1       175   \n",
       "1       1.224500e+17       0.968160        176       369   \n",
       "2       1.224500e+17       0.969560        370       703   \n",
       "3       1.224430e+17       0.949734        704       827   \n",
       "4       1.224570e+17       0.987373        828       941   \n",
       "...              ...            ...        ...       ...   \n",
       "166071  1.250010e+17       8.007164   34784039  34784103   \n",
       "166072  1.250010e+17       8.007407   34784104  34784155   \n",
       "166073  1.259250e+17      10.559387   34784156  34784320   \n",
       "166074  1.255490e+17       9.519977   34784321  34784412   \n",
       "166075  1.254170e+17       9.156794   34784413  34784488   \n",
       "\n",
       "                           post_date  total_retweets_over_15_days  outbreak  \n",
       "0      2011-10-07 22:14:22.000041600                          174     False  \n",
       "1      2011-10-07 23:14:08.999980800                          193     False  \n",
       "2      2011-10-07 23:16:09.999984000                          333     False  \n",
       "3      2011-10-07 22:47:36.999974400                          123     False  \n",
       "4      2011-10-07 23:41:48.999984000                          113     False  \n",
       "...                              ...                          ...       ...  \n",
       "166071 2011-10-15 00:10:19.000012800                           64     False  \n",
       "166072 2011-10-15 00:10:39.999964800                           51     False  \n",
       "166073 2011-10-17 13:25:30.999648000                          164     False  \n",
       "166074 2011-10-16 12:28:46.000012800                           91     False  \n",
       "166075 2011-10-16 03:45:46.999958400                           75     False  \n",
       "\n",
       "[166076 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def merge_data(data, index):\n",
    "    df = data\n",
    "    df[\"tweet_id\"] = np.nan\n",
    "    df['post_date'] = np.nan\n",
    "    df['outbreak'] = np.nan\n",
    "    \n",
    "    temp = index[['post_date', 'outbreak', 'tweet_id']]\n",
    "    start_stop = index[['start_ind', 'end_ind']].values.tolist()\n",
    "    count = 0\n",
    "    \n",
    "    for start, stop in start_stop:\n",
    "        df.loc[(start-1):(stop-1),['post_date', 'outbreak', 'tweet_id']] = temp.loc[count].values\n",
    "        \n",
    "        # print(start-1, \" \", stop-1)\n",
    "        # print( df.loc[(start-1):(stop-1),['post_date', 'outbreak', 'tweet_id']] )\n",
    "        # print( temp.loc[count].shape)\n",
    "        #  df.loc[(start-1):(stop-1),'outbreak'] = index['outbreak'].loc[count]\n",
    "        #  df.loc[(start-1):(stop-1),'tweet_id'] = index['tweet_id'].loc[count]\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "    return df\n",
    "\n",
    "data_next = merge_data(data, index)\n",
    "data_next['post_date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_next.to_csv(\"merged_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_next.groupby('post_date').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "#     Combine the data sets\n",
    "# \"\"\"\n",
    "# def merge(data):\n",
    "#     idx = index.to_dict('records')\n",
    "#     flatten = lambda t: [item for sublist in t for item in sublist]\n",
    "#     tweet_id = [( 1 + row['end_ind'] - row['start_ind']) * [str(row['tweet_id'])] for row in idx]\n",
    "#     outbreak = [( 1 + row['end_ind'] - row['start_ind']) * [str(row['outbreak'])] for row in idx]\n",
    "#     post_date = [( 1 + row['end_ind'] - row['start_ind']) * [str(row['post_date'].strftime('%Y-%m-%d'))] for row in idx]\n",
    "#     total_retweets_over_15_days = [( 1 + row['end_ind'] - row['start_ind']) * [str(row['total_retweets_over_15_days'])] for row in idx]\n",
    "\n",
    "#     data['tweet_id'] = flatten(tweet_id)\n",
    "#     data['outbreak'] = flatten(outbreak)\n",
    "#     data['post_date'] = flatten(post_date)\n",
    "#     data['total_retweets_over_15_days'] = flatten(total_retweets_over_15_days)\n",
    "\n",
    "#     \"\"\"\n",
    "#         Convert data types\n",
    "#     \"\"\"\n",
    "#     data['tweet_id'] = pd.to_numeric(data['tweet_id'])\n",
    "#     data['total_retweets_over_15_days'] = pd.to_numeric(data['total_retweets_over_15_days'])\n",
    "#     data['post_date'] = pd.to_datetime(data['post_date'])\n",
    "#     data['outbreak'] = data['outbreak'].apply(lambda x: True if x == 'True' else False)\n",
    "#     return data\n",
    "\n",
    "# data_index = merge(data)\n",
    "# data_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv(\"check_outbreaks.csv\")\n",
    "total_tweets_grouped =  data\n",
    "total_tweets_grouped.groupby('outbreak').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = lambda x : '{:.5f}'.format(x)\n",
    "vb = data[data['tweet_id'] == 125000000000000000]\n",
    "vb['post_date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " Break into time windows\n",
    "\"\"\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def gen_groups(window_length_hrs = 1, window_size_secs = 10):\n",
    "    gb = data.groupby('tweet_id')\n",
    "    digest = pd.DataFrame()\n",
    "    for name, group in gb:\n",
    "        group = group[group['relative_time_second'] < 3600 * window_length_hrs]\n",
    "        group['window'] = group['relative_time_second'].apply(lambda x: x//window_size_secs)\n",
    "        # print(\"Name \", name)\n",
    "        for n, sg in group.groupby('window'):\n",
    "            nf = sg['number_of_followers']\n",
    "            tweet_window = {'tweet_id':name, 'median_followers' : nf.median(), \n",
    "                            'count_retweets': nf.count(), 'sum_followers': nf.sum(), \n",
    "                            'outbreak': sg['outbreak'].max(),\n",
    "                            'window': n,\n",
    "                            'post_date': sg['post_date'].max()}\n",
    "            yield tweet_window\n",
    "\n",
    "g = gen_groups()\n",
    "df = pd.DataFrame(list(g))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HELLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Save the grouped tweets to a new file\n",
    "    uncomment to resave\n",
    "\"\"\"\n",
    "df.to_csv('grouped_cascades_tagged_2020_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    START HERE AFTER PREPROCESSING\n",
    "\"\"\"\n",
    "grouped_cascades = pd.read_csv(\"grouped_cascades_tagged_2020_v2.csv\")\n",
    "grouped_cascades['window'] =grouped_cascades['window'].astype('int')\n",
    "grouped_cascades.drop(['Unnamed: 0'], 1, inplace=True)\n",
    "\n",
    "total_tweets_group =  grouped_cascades\n",
    "total_tweets_group.groupby('outbreak').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_cascades['post_date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vb = grouped_cascades[grouped_cascades['tweet_id'] == 125000000000000000]\n",
    "vb[vb['window']>=310]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_cascades.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = lambda x : '{:.5f}'.format(x)\n",
    "vb = grouped_cascades[grouped_cascades['tweet_id'] == 125000000000000000]\n",
    "vb[vb['window']>=310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Backfill tweets that dont have tweets for certain windows\n",
    "\"\"\"\n",
    "def backfill_missing(data):\n",
    "    vals_wind = [x for x in range(360)]\n",
    "    unq_tweet = data.tweet_id.unique()\n",
    "    timestamps = [vals_wind for y in unq_tweet ]\n",
    "    df = pd.DataFrame({'tweet_index':unq_tweet, 'timestamps':timestamps}).explode(column='timestamps')\n",
    "    cascades_merged = pd.merge(df, data,  how='left', left_on=['tweet_index','timestamps'], right_on = ['tweet_id','window'])\n",
    "\n",
    "    # Fil with zeros if no data for window\n",
    "    cascades_merged[['median_followers', 'count_retweets', 'sum_followers']] = cascades_merged[['median_followers', 'count_retweets', 'sum_followers']].fillna(value=0)\n",
    "    cascades_merged['window'] = pd.to_numeric(cascades_merged['timestamps'])\n",
    "\n",
    "    #Drop duplicate columns\n",
    "    cascades_merged.drop(['timestamps', 'tweet_id'], 1, inplace=True)\n",
    "\n",
    "    # Fill down with data for outbreak and postdate\n",
    "    cascades_merged['post_date'] = cascades_merged['post_date'].ffill(axis = 0)\n",
    "    cascades_merged['outbreak'] = cascades_merged['outbreak'].ffill(axis = 0) \n",
    "\n",
    "    cascades_merged['post_date'] = pd.to_datetime(cascades_merged['post_date'])\n",
    "    return cascades_merged\n",
    "\n",
    "cascades_merged = backfill_missing(grouped_cascades)\n",
    "cascades_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Training vs Testing Set\n",
    "    The 15 days were divided into two parts, the first 7 days were used for training and the next 8 days were used for test.\n",
    "    94,254 tweets in the test set.\n",
    "    Test: 2856 unique tweets (55%)  Train: 2377 unique tweets (45%)\n",
    "\"\"\"\n",
    "pd.options.display.float_format = lambda x : '{:.5f}'.format(x)\n",
    "def test_train_split(data):\n",
    "    train = data[data.post_date < '2011-10-14']\n",
    "    test = data[data.post_date > '2011-10-14']\n",
    "    \n",
    "#     row = train.loc[977351]\n",
    "#     print(row)\n",
    "#     train.drop(index=977351, inplace=True)\n",
    "    count_test = len(test.tweet_index.unique())\n",
    "    count_train = len(train.tweet_index.unique())\n",
    "    #total = len(df.tweet_index.unique())\n",
    "    total = len(data.tweet_index.unique())\n",
    "    print(\"Unique cascades \", total)\n",
    "    print(\"tot \", (count_test + count_train))\n",
    "    print(\"Test: {} unique tweets ({:.0%})  Train: {} unique tweets ({:.0%})\".format(count_test, float(count_test/total), count_train, float(count_train/total)))\n",
    "    return train, test\n",
    "\n",
    "print(\"Total tweet and retweets: {}\".format(grouped_cascades.shape[0]))\n",
    "train, test = test_train_split(cascades_merged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('tweet_index').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.groupby('tweet_index').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.groupby('tweet_index')['window'].count().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vb = test[test['tweet_index'] == 125000000000000000]\n",
    "vb[vb['window']>=310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.iloc[-5:-1]\n",
    "test.iloc[-362]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Create Numpy array for each tweet\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "def get_numpy_arrays(data, x=True):\n",
    "    gb = data.groupby('tweet_index')\n",
    "#     values = np.empty([360, 4])\n",
    "    values  = []     \n",
    "#     print(values.shape)\n",
    "    for name, group in gb:\n",
    "        group.drop(['tweet_index', 'post_date'], 1, inplace=True)\n",
    "        if x:\n",
    "            group.drop(['outbreak'], 1, inplace=True)\n",
    "#             print(group.values.shape)\n",
    "\n",
    "            d = group.values.tolist()\n",
    "            \n",
    "        else:\n",
    "            group = group[['outbreak']].max()\n",
    "            d = group[0]\n",
    "        values.append(d)\n",
    "#         values = np.concatenate((values,d))\n",
    "           \n",
    "    return values\n",
    "\n",
    "# median_followers \tcount_retweets \tsum_followers, window\n",
    "train_input_x = np.stack(np.array(get_numpy_arrays(train, True)))\n",
    "test_input_x = np.stack(np.array(np.array(get_numpy_arrays(test, True))))\n",
    "# train_input_y = np.array(get_numpy_arrays(train, False))\n",
    "# test_input_y = np.array(get_numpy_arrays(test, False))\n",
    "train_input_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(np.array(train_input_x)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(train_input_x, key=len)[0]\n",
    "# gb = train.groupby('tweet_index')\n",
    "# for name, group in gb:\n",
    "    \n",
    "#     group.drop(['tweet_index', 'post_date'], 1, inplace=True)\n",
    "#     group.drop(['outbreak'], 1, inplace=True)\n",
    "#     d = group.values\n",
    "#     break\n",
    "# d\n",
    "# d.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# median_followers \tcount_retweets \tsum_followers, window\n",
    "train_input_x = np.array(get_numpy_arrays(train, True))\n",
    "train_input_y = np.array(get_numpy_arrays(train, False))\n",
    "test_input_x = np.array(get_numpy_arrays(test, True))\n",
    "test_input_y = get_numpy_arrays(test, False)\n",
    "train_input_x[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_x = train_input_x.reshape((train_input_x.shape[0], 360, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_input_x.shape, \" \" ,  train_input_x[1].shape)  #360 windows and 4 columns (wiht median_followers count_retweets sum_followers and window number)\n",
    "print(train_input_y.shape, \" \" ,  train_input_y[1])  #1 output for cascade\n",
    "# (2377,)   (360, 4)\n",
    "# (2377,)   True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST WHAT IS GOING ON\n",
    "mnist = keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape, \" \" ,  x_train[0].shape)  #28 rows and 28 columns\n",
    "print(y_train.shape, \" \" ,  y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "#     Clean up training set\n",
    "# \"\"\"\n",
    "# train_X = train.drop(['post_date'], axis=1)\n",
    "# train_X.head()\n",
    "# train_X = train.drop(['outbreak'], axis=1)\n",
    "# train_Y = train['outbreak']\n",
    "# train_X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "input_dim = 4\n",
    "units = 64\n",
    "output_size = 2  # labels are from 0 to 9\n",
    "\n",
    "# Build the RNN model\n",
    "def build_model():\n",
    "    # Wrapping a LSTMCell in a RNN layer\n",
    "    lstm_layer = keras.layers.RNN(\n",
    "        keras.layers.LSTMCell(units), input_shape=(None, input_dim)\n",
    "    )\n",
    "    model = keras.models.Sequential(\n",
    "        [\n",
    "            lstm_layer,\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Dense(output_size),\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_y.reshape((2377, 0, 1)).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=\"sgd\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_input_x, train_input_y, validation_data=(test_input_x, test_input_y), batch_size=batch_size, epochs=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on dengue fever group\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Add a LSTM layer with 128 internal units.\n",
    "model.add(layers.LSTM(128, input_shape=(train.shape[1],\n",
    "               train.shape[2])))\n",
    "model.add(layers.Dense(50, activation='relu'))\n",
    "model.add(layers.Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')  # mean absolute error to evaluate its performance\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train, train_y, epochs=epoch_count, batch_size=72, \n",
    "                        validation_data=(test_X, test_y), verbose=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Model\n",
    "\"\"\"\n",
    "model = models.Sequential() \n",
    "model.add(LSTM(103, input_shape=(train.shape[1],\n",
    "               train.shape[2])))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print(\"Test \", count_train, \" Test \", count_test, \" :\")\n",
    "#test.s\n",
    "\n",
    "# df =  data.sort_values(by='outbreak')\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.sort_values(by='post_date', ascending = False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "#The 15 days were divided into two parts, the first 7 days were used for training and the next 8 days were used for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B. Retweet count feature extractor\n",
    "# B1. can represent a cascade as a sequence of time windows after monitoring each tweet up to Timeo\n",
    "# Each of these time windows has zero or more number of retweet counts. \n",
    "# b2. use one-hot encoder to represent the total number of retweets in each time window to a vector\n",
    "# B3. we have a sequence of vectors for a sequence of time windows corresponding to each tweet.\n",
    "# B4. fed through single GRU units to extract latent features\n",
    "# B5. deplye attention layer\n",
    "# viral if retweettotal > N, where N is some predefined threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \"\"\"\n",
    "Our model is going to be a Long Short-Term Memory (LSTM) RNN. \n",
    "The recurrent layer is followed by a few dense layers, \n",
    "activated with Scaled Exponential Linear Unit (SELU) and \n",
    "regularized by batch normalization.\n",
    "\"\"\"\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
    "\n",
    "# The output of GRU will be a 3D tensor of shape (batch_size, timesteps, 256)\n",
    "model.add(layers.GRU(256, return_sequences=True))\n",
    "\n",
    "# The output of SimpleRNN will be a 2D tensor of shape (batch_size, 128)\n",
    "model.add(layers.SimpleRNN(128))\n",
    "\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.guru99.com/rnn-tutorial.html\n",
    "import numpy as np\n",
    "n_inputs = 4\n",
    "n_neurons = 6\n",
    "n_timesteps = 2\n",
    "\n",
    "#The data is a sequence of a number from 0 to 9 and divided into three batches of data.\n",
    "## Data \n",
    "X_batch = np.array([\n",
    "        [[0, 1, 2, 5], [9, 8, 7, 4]], # Batch 1\n",
    "        [[3, 4, 5, 2], [0, 0, 0, 0]], # Batch 2\n",
    "        [[6, 7, 8, 5], [6, 5, 4, 2]], # Batch 3\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder\n",
    "#     None: Unknown and will take the size of the batch\n",
    "#     n_timesteps: Number of time the network will send the output back to the neuron\n",
    "#     n_inputs: Number of input per batch\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_timesteps, n_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The higher the loss function, the dumber the model is. \n",
    "\"\"\"\n",
    "Traditional NN produces the output by multiplying the input with the weight and the activation function. \n",
    "With an RNN, this output is sent back to itself number of time. We call timestep the amount of time \n",
    "the output becomes the input of the next matrice multiplication. \n",
    "\"\"\"\n",
    "\n",
    "basic_cell = tf.keras.layers.SimpleRNNCell(units=n_neurons)\n",
    "#basic_cell = tf.compat.v1.nn.rnn_cell.BasicRNNCell(num_units=n_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)\n",
    "#outputs, states = tf.keras.layers.RNN(basic_cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val = outputs.eval(feed_dict={X: X_batch})\n",
    "print(states.eval(feed_dict={X: X_batch}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
